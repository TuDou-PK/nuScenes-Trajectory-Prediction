{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM + LinearX, LinearY\n",
        "\n",
        "Cite from https://github.com/jjbecomespheh/Trajectory_Prediction_Using_nuScenes_Dataset \n",
        "\n",
        "- This model uses basic LSTM, which use incremental prediction, in the iteration, it predicts the next point (x, y) of the trajectory in turn, and then use this new (x, y) as the training trajectory point to add to the sequence.\n",
        "\n",
        "- We not cite their ADE and FDE result directly, because \n",
        " - They used their own processed datasets, which is not fit our requirements. Such as they only use (x, y) rather than (x, y, v, a, r) (v: speed, a: acceleration, r: heading rate).\n",
        " - Their prediction output not met the requirements of nuScenes prediction task. The offcial made 6 second predictions at 2 Hz, n_timesteps is 12. So we need to predict 12 points of single trajectory. However, their output is 6 points.\n",
        "\n",
        "- For the above reasons, so we reconstruct their part of the code to meet our requirements."
      ],
      "metadata": {
        "id": "W6YagN6mLFqw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYPBqYJ3pTm3"
      },
      "source": [
        "# Import "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRzFooxrIjzf",
        "outputId": "f8920263-01ce-4da4-ac3b-a2fd2014770e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nuscenes-devkit tools \n",
        "!pip install nuscenes-devkit"
      ],
      "metadata": {
        "id": "ez7zZ7IMIvXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6npmqynAIIAF"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "\n",
        "from nuscenes import NuScenes\n",
        "from nuscenes.eval.prediction import metrics\n",
        "from nuscenes.eval.prediction.data_classes import Prediction\n",
        "from nuscenes.prediction import PredictHelper\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WVqx9lxpxvv"
      },
      "source": [
        "# Import data "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can import the file \"np_trajectory_data_22_with_VAR.npy\" from [Link](https://drive.google.com/drive/folders/118Z18sWEg4CqHAhFcYmDqXvDj2qk4YtI?usp=sharing), it's the same with \"trajectory\" data in \"DL-Project.ipynb\" at code 3.3. Just for testing convenience \n",
        "\n",
        "`trajectory = get_trajectories(trajectory_data, uni_instance_ids)`\n",
        "\n",
        "\n",
        "`np.save('np_trajectory_data_22_with_VAR.npy', trajectory)\n",
        "`"
      ],
      "metadata": {
        "id": "by8GOqypS__-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2g__yRQ4IIAI"
      },
      "outputs": [],
      "source": [
        "trajectory = np.load(\"/content/drive/MyDrive/DL_nuScenes/np_trajectory_data_22_with_VAR.npy\", allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6w0JzQC935b",
        "outputId": "d0d09e21-bf5d-460d-f304-a33896cd6b1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17503,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "trajectory.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9_-5NEiUbfG"
      },
      "outputs": [],
      "source": [
        "train_data = trajectory[0:int(len(trajectory)*0.6)]\n",
        "val_data = trajectory[int(len(trajectory)*0.6): int(len(trajectory)*0.8)]\n",
        "test_data = trajectory[int(len(trajectory)*0.8):]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using GPU"
      ],
      "metadata": {
        "id": "ba9pCp7xJwN3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-j5bXIRVB4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a3927b-5ecf-42a1-cca6-f97d52492fe4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SgYiOgVqArB"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V__XqhJPIIAJ"
      },
      "outputs": [],
      "source": [
        "def sliding_windows(data, seq_length):\n",
        "    x = []\n",
        "    predicted_ls = []\n",
        "    for i in range(len(data)-seq_length):\n",
        "        _x = data[i:(i+seq_length)]\n",
        "        predicted = data[i+seq_length]\n",
        "        x.append(_x)\n",
        "        predicted_ls.append(predicted)\n",
        "    return np.array(x), np.array(predicted_ls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t90jVfkYdNnq"
      },
      "outputs": [],
      "source": [
        "# This method is to convert X and Y values into tensors and reshape them\n",
        "def conv_and_reshape(x, y):\n",
        "\n",
        "    X = torch.tensor(x, dtype=torch.float32)\n",
        "    Y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    if len(X.shape) == 1:\n",
        "        X = torch.reshape(X, (X.shape[0],1))\n",
        "        Y = torch.reshape(Y, (Y.shape[0],1))\n",
        "    elif len(X.shape) == 2:\n",
        "        X = torch.reshape(X, (X.shape[0],X.shape[1],1))\n",
        "        Y = torch.reshape(Y, (Y.shape[0],Y.shape[1],1))\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MQy138cIIAL"
      },
      "outputs": [],
      "source": [
        "def get_data(trajectory, seq_length):\n",
        "    tra = []\n",
        "    for t in trajectory:\n",
        "        tra.append(t[2:4])\n",
        "    \n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    xy = scaler.fit_transform(tra)\n",
        "    \n",
        "    \n",
        "    x = xy[:, 0]\n",
        "    y = xy[:, 1]\n",
        "    \n",
        "    x, exp_x = sliding_windows(x, seq_length)\n",
        "    y, exp_y = sliding_windows(y, seq_length)\n",
        "    \n",
        "    dataX, dataY = conv_and_reshape(x,y)\n",
        "    exp_x, exp_y = conv_and_reshape(exp_x, exp_y)\n",
        "    \n",
        "    return dataX, dataY, exp_x, exp_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXW59GtPvq9T"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkonZaVLJNuE"
      },
      "outputs": [],
      "source": [
        "class LSTM_0_1(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(LSTM_0_1, self).__init__()\n",
        "        \n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        # Tensors in (batch, seq, feature)\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                            num_layers=num_layers, batch_first=True)\n",
        "        \n",
        "        self.fc1 = nn.Linear(hidden_size, 1)\n",
        "        self.fc2 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        h_0 = Variable(torch.zeros(\n",
        "            self.num_layers, data.size(0), self.hidden_size)).to(device)\n",
        "        \n",
        "        c_0 = Variable(torch.zeros(\n",
        "            self.num_layers, data.size(0), self.hidden_size)).to(device)\n",
        "        \n",
        "        # Propagate input through LSTM\n",
        "        out, (_, _) = self.lstm(data, (h_0, c_0))\n",
        "\n",
        "        out = out[:,-1,:]\n",
        "        \n",
        "        out_x = self.fc1(out)\n",
        "        out_y = self.fc2(out)\n",
        "\n",
        "        return out_x, out_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgS9UANmyxki"
      },
      "source": [
        "###### Model instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4AqWtYivpiY"
      },
      "outputs": [],
      "source": [
        "lstm_0_1 = LSTM_0_1(2, 2, 1)\n",
        "lstm_0_1 = lstm_0_1.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-k5KQ3nxWR6y"
      },
      "outputs": [],
      "source": [
        "learning_rate_0_1 = 0.001\n",
        "loss_func_0_1 = torch.nn.MSELoss()\n",
        "optimizer_0_1 = torch.optim.Adam(lstm_0_1.parameters(), lr=learning_rate_0_1)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer_0_1, step_size=3, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TjOrouCyluv"
      },
      "source": [
        "###### train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKcop8_jIdi7"
      },
      "outputs": [],
      "source": [
        "def clean_nan(tra):\n",
        "    tra_new = []\n",
        "    for t in tra:\n",
        "        if math.isnan(t[4]) or math.isnan(t[5]) or math.isnan(t[6]):\n",
        "            continue\n",
        "        else:\n",
        "            tra_new.append(t)\n",
        "    return tra_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxeF-d7zwR_r"
      },
      "outputs": [],
      "source": [
        "def train_0(trajectory, lstm, seq_length, epoch, optimizer, loss_func):\n",
        "    loss_plot = []\n",
        "    lstm.train()\n",
        "\n",
        "    log_interval = 1000\n",
        "    train_loss = 0\n",
        "    rep_loss = 0 \n",
        "\n",
        "    for i, tra in enumerate(trajectory):\n",
        "        tra = clean_nan(tra)\n",
        "        if len(tra) < 20 or tra[0][-1] == 0:  # \n",
        "            continue\n",
        "        optimizer.zero_grad()\n",
        "        dx, dy, ex, ey = get_data(tra, seq_length)\n",
        "        cat_data = torch.cat([dx, dy], dim = 2)\n",
        "\n",
        "        len_dx = len(dx)\n",
        "\n",
        "        #GPU\n",
        "        cat_data = cat_data.to(device)\n",
        "        label = torch.tensor([float(tra[0][-1])]*len_dx).to(device)\n",
        "\n",
        "        predicted_output_x, predicted_output_y = lstm(cat_data)\n",
        "        ex = ex.to(device)\n",
        "        ey = ey.to(device)\n",
        "        loss_x = loss_func(predicted_output_x, ex)\n",
        "        loss_y = loss_func(predicted_output_y, ey)\n",
        "\n",
        "        loss = loss_x + loss_y\n",
        "        train_loss += loss\n",
        "        rep_loss += loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % log_interval == 0 and i > 0:\n",
        "            print(f\"| Epoch {epoch:3d} | {i:5d}/{len(trajectory):5d} batches | loss: {rep_loss/log_interval:8.3f}\")\n",
        "            rep_loss = 0\n",
        "    return train_loss/len(trajectory)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMVPb97Eyo_k"
      },
      "source": [
        "###### train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax6PZvJhwkEg",
        "outputId": "e06774a5-1674-4203-b8e2-ddefb430ca43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Epoch   0 |  1000/10501 batches | loss:    0.417\n",
            "| Epoch   0 |  2000/10501 batches | loss:    0.237\n",
            "| Epoch   0 |  4000/10501 batches | loss:    0.205\n",
            "| Epoch   0 |  7000/10501 batches | loss:    0.149\n",
            "| Epoch   0 |  8000/10501 batches | loss:    0.037\n",
            "| Epoch   0 |  9000/10501 batches | loss:    0.033\n",
            "| Epoch   1 |  1000/10501 batches | loss:    0.024\n",
            "| Epoch   1 |  2000/10501 batches | loss:    0.022\n",
            "| Epoch   1 |  4000/10501 batches | loss:    0.043\n",
            "| Epoch   1 |  7000/10501 batches | loss:    0.062\n",
            "| Epoch   1 |  8000/10501 batches | loss:    0.023\n",
            "| Epoch   1 |  9000/10501 batches | loss:    0.022\n",
            "| Epoch   2 |  1000/10501 batches | loss:    0.019\n",
            "| Epoch   2 |  2000/10501 batches | loss:    0.017\n",
            "| Epoch   2 |  4000/10501 batches | loss:    0.037\n",
            "| Epoch   2 |  7000/10501 batches | loss:    0.055\n",
            "| Epoch   2 |  8000/10501 batches | loss:    0.022\n",
            "| Epoch   2 |  9000/10501 batches | loss:    0.021\n"
          ]
        }
      ],
      "source": [
        "t_0 = []\n",
        "seq_length = 8\n",
        "for epoch in range(6):\n",
        "    train_loss_0 = train_0(train_data, lstm_0_1, seq_length, epoch, optimizer_0_1, loss_func_0_1)\n",
        "    t_0.append(train_loss_0.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JamoQhEMs4mj"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjEAk6MQ0ymQ"
      },
      "source": [
        "###### look_ahead_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYlWrVuBZSB6"
      },
      "outputs": [],
      "source": [
        "def look_ahead_test(lstm, trajectory, seq_length, frames_to_predict, start):\n",
        "    traj_xy = []  \n",
        "    for t in trajectory:\n",
        "        traj_xy.append(t[2:4])\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    xy = scaler.fit_transform(traj_xy)\n",
        "    xs = xy[:,0]\n",
        "    ys = xy[:,1]\n",
        "    x, expected_x = sliding_windows(xs, seq_length)\n",
        "    y, expected_y = sliding_windows(ys, seq_length)\n",
        "    x, expected_x = [x[start]], expected_x[start:]\n",
        "    y, expected_y = [y[start]], expected_y[start:]\n",
        "\n",
        "    original_x, original_y = xs[:start+seq_length], ys[:start+seq_length]\n",
        "\n",
        "    dataX, dataY = conv_and_reshape(x,y)\n",
        "\n",
        "    original_x, original_y = conv_and_reshape(original_x, original_y)\n",
        "    expected_x, expected_y = conv_and_reshape(expected_x, expected_y)\n",
        "\n",
        "\n",
        "    lstm.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predicted_data = []\n",
        "        cat_data = torch.cat([dataX, dataY], dim=2)\n",
        "        cat_data = cat_data.to(device)\n",
        "        for i in range(frames_to_predict):\n",
        "\n",
        "            predicted_output_x, predicted_output_y = lstm(cat_data)\n",
        "            combined_predicted_output = torch.cat([predicted_output_x, predicted_output_y], dim=1)\n",
        "\n",
        "            new_cat_data = cat_data[0][1:]\n",
        "\n",
        "            new_data = torch.cat([new_cat_data, combined_predicted_output])\n",
        "            cat_data = torch.reshape(new_data, (1,new_data.shape[0], new_data.shape[1]))\n",
        "            \n",
        "            combined_predicted_output = combined_predicted_output.cpu().data\n",
        "            data_predict = scaler.inverse_transform(combined_predicted_output)\n",
        "            predicted_data.append(data_predict[0])\n",
        "\n",
        "        combined_original_traj = torch.cat([original_x, original_y], dim=1)\n",
        "        combined_expected_traj = torch.cat([expected_x, expected_y], dim=1)\n",
        "\n",
        "        data_original = scaler.inverse_transform(combined_original_traj)\n",
        "        data_expected = scaler.inverse_transform(combined_expected_traj)\n",
        "\n",
        "        pred_data = np.reshape(predicted_data, (len(predicted_data),len(predicted_data[0])))\n",
        "    return pred_data, data_expected, data_original\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-l4FbPg-ZpI"
      },
      "outputs": [],
      "source": [
        "frames_to_predict = 12\n",
        "p_one_mode = np.array([[1.]])\n",
        "\n",
        "\n",
        "def traj2modes(trajs):\n",
        "    return np.array([trajs])\n",
        "\n",
        "\n",
        "def My_metrics_with_nunsceces(lstm, test_data, seq_length, frames_to_predict, start):\n",
        "    results_look_ahead = {}\n",
        "    avg_ade = 0\n",
        "    avg_fde = 0\n",
        "    avg_missRate = 0\n",
        "    length = len(test_data)\n",
        "    \n",
        "    for tra in tqdm.tqdm(test_data):\n",
        "        tra = clean_nan(tra)\n",
        "        if len(tra) < 20: \n",
        "            length -= 1\n",
        "            continue\n",
        "        if tra[0][-1] == 0:\n",
        "            continue\n",
        "        \n",
        "        predicted_data, data_expected, data_original = look_ahead_test(lstm, tra, seq_length, frames_to_predict, start)\n",
        "        \n",
        "        modes = data_expected.shape[0]\n",
        "        if modes > 12:\n",
        "            data_expected = data_expected[0:12]\n",
        "        elif modes < 12:\n",
        "            predicted_data = predicted_data[0:modes]\n",
        "        x_one_mode, y_one_mode = traj2modes(predicted_data), traj2modes(data_expected)\n",
        "\n",
        "        ade = metrics.min_ade_k(x_one_mode, y_one_mode, p_one_mode)\n",
        "        fde = metrics.min_fde_k(x_one_mode, y_one_mode, p_one_mode)\n",
        "        missRate = metrics.miss_rate_top_k(x_one_mode, y_one_mode, p_one_mode, 2)\n",
        "\n",
        "\n",
        "        avg_ade += ade\n",
        "        avg_fde += fde\n",
        "        avg_missRate += missRate\n",
        "    avg_ade = avg_ade/length\n",
        "    avg_fde = avg_fde/length\n",
        "    avg_missRate = 1 - avg_missRate/length\n",
        "    print()\n",
        "    print(\"avg_ade:\",avg_ade[0][0])\n",
        "    print(\"avg_fde:\",avg_fde[0][0])\n",
        "    print(\"avg_missRate:\",avg_missRate[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6phdVZF-Lnc",
        "outputId": "6fa60cb0-f633-4f59-a62f-23237bf35f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3501 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  after removing the cwd from sys.path.\n",
            "100%|██████████| 3501/3501 [00:13<00:00, 261.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "avg_ade: 4.026117876916457\n",
            "avg_fde: 7.337618028983116\n",
            "avg_missRate: 0.6660949113779302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "My_metrics_with_nunsceces(lstm_0_1, test_data, seq_length, frames_to_predict, 0)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}